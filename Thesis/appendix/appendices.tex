\cleardoublepage
\chapter{LLM Prompts.}
\label{ch:appendices}

This section demonstrates the prompts used in this work.

\input{appendix/prompt_base_qa}
\input{appendix/prompt_base_qa_qwen}
\input{appendix/prompt_base_qa_all}
\input{appendix/prompt_base_locomo}
\input{appendix/prompt_base_locomo_all}
\input{appendix/prompt_evaluation_judge}

\chapter{Cost Analysis}

\noindent Figure \ref{fig:qa_cost} presents token consumption to answer all questions in the four datasets.

\input{appendix/cost/qa_cost_group}

\noindent Figure \ref{fig:qa_cost_qwen} presents token consumption to answer all questions in the four datasets using QWen2.5-14B.

\input{appendix/cost/qa_cost_group_wqen}

\noindent Figure \ref{fig:qa_token_prompt_tech} shows token consumption using ColBERTV2 with various LLMs and QA approaches.

\input{appendix/cost/qa_cost_prompt_tech}

\noindent Figure \ref{fig:qa_avg_token_prompt_tech} shows average token consumption for each question answer pair using ColBERTV2 with various LLMs and QA approaches.

\input{appendix/cost/qa_avg_cost_prompt_tech}
