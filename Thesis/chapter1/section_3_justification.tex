\section{Justification}
\label{sec:justification}

A robust agent-based system is essential for advancing state-of-the-art benchmarks in natural language long-input tasks, particularly QA and MHQA, which assess both language understanding and reasoning capabilities \cite{10.1561/1500000102}. These tasks are commonly evaluated using benchmark datasets such as LoCoMo \cite{maharana-etal-2024-evaluating}, HotpotQA \cite{yang2018hotpotqa}, MuSiQue \cite{trivedi2021musique}, and 2WikiMultiHopQA \cite{ho-etal-2020-constructing}.

\noindent Beyond academic benchmarks, effective agent-based architectures hold significant real-world potential.  They could enhance QA systems, particularly in specialized domains such as law, where documents tend to be lengthy and complex \cite{regnlp-ws-2025-1}. Additionally, they could improve personal companion and psychological counseling applications, where maintaining continuity and context over time is critical for meaningful and supportive interactions \cite{Zhong_Guo_Gao_Ye_Wang_2024}. In the medical domain, where precision is critical and knowledge evolves rapidly, reliable QA systems remain essential, and recent work shows that current systems still fall short of the performance needed for such high-stakes applications \cite{ALONSO2024102938}.

\noindent Together, these motivations highlight the pressing need for agent-based architectures that are adaptable, robust, and capable of supporting complex reasoning across diverse domains and languages, particularly for QA tasks.