\section{Context}
\label{sec:context}

Large Language Models (LLMs) have consistently demonstrated strong performance in various natural language tasks, enabling applications such as conversational interfaces and question answering \cite{minaee2024largelanguagemodelssurvey}. Recent advancements in hardware and model architectures have led to the development of models capable of handling large context windows, including GPT-3.5 Turbo with $16K$ tokens, GPT-4 with up to $32K$ tokens, and Gemini 1.5 Pro, which remarkably supports a $2M$-token context window
\cite{liu2023lostmiddlelanguagemodels}\cite{openai2024gpt4technicalreport}\cite{geminiteam2024gemini15unlockingmultimodal}. Despite these efforts, certain problems, such as long-document question answering, remain challenging. Studies have shown that LLM performance tends to degrade when relevant information appears in the middle of the context window rather than at the beginning or end, a phenomenon commonly referred to as \textit{"lost in the middle"} \cite{liu2023lostmiddlelanguagemodels}. Additionally, naively increasing the context length in transformer-based architectures incurs prohibitively high computational costs \cite{kitaev2020reformerefficienttransformer}.

\noindent To address these limitations, researchers have explored alternative strategies that equip LLMs with long-term memory, enabling them to retrieve and reason over external information. Retrieval Augmented Generation (RAG), a widely adopted approach, integrates new knowledge into LLMs by retrieving relevant content from an external source \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. However, RAG alone often struggles to synthesize information from multiple sources and to reason effectively about retrieved content, especially in complex multi-step natural language tasks \cite{NEURIPS2024_6ddc001d}\cite{liang2024kagboostingllmsprofessional}.

\noindent Building on these ideas, recent work has proposed a more structured framework, \textit{Cognitive Language Agents}, that integrates principles from cognitive science to design intelligent agents that consist of three key components: memory, action and decision-making. Memory is further categorized into four types: \textit{working memory}, which stores perceptual inputs and active knowledge; \textit{episodic memory}, which retains past experiences; \textit{semantic memory}, which contains factual knowledge about the world; and \textit{procedural memory}, which encodes the rules and functions that govern the agent's interaction with its environment. The agent's internal actions dictate how it engages with these memory components, retrieving, updating, and organizing knowledge to support more coherent reasoning and learning over time \cite{sumers2024cognitive}. Many LLM-based systems designed to enhance long-range information retention and reasoning capabilites can be analyzed through this framework, including the following examples.

\noindent Memory GPT (MemGPT) is a language agent that manages multiple storage tiers, effectively allowing it to process more input despite its limited context window. The agent maintains procedural memory to encode the rules for reading from and writing to these storage tiers. During reasoning, MemGPT retrieves past interactions using dense retrieval, drawing from either an episodic or semantic database. Retrieved information is then loaded into its working memory \cite{packer2024memgptllmsoperatingsystems}.

\noindent GraphReader is a language agent specifically designed for handling long-input tasks using structured data. In particular, it utilizes a graph as its long-term memory. This graph is constructed offline by prompting an LLM to extract entities and their related facts, with each vertex representing an entity and its associated information. Once the graph is built, the system retrieves the most relevant nodes using dense retrieval to serve as entry points for exploration. The agent then navigates the graph using a set of predefined functions, such as searching neighboring nodes. The agent follows a rationale-driven plan to aid in decision-making and autonomously determines when it has gathered sufficient information to generate a response \cite{li2024graphreaderbuildinggraphbasedagent}.

\noindent Further advances have introduced other data structured approaches that explicitly differentiate between semantic and episodic memory. For example, AriGraph is an agent whose memory module consists of two types of vertices, semantic vertices, which represent entities, and are connected by semantic edges representing relationships; and episodic vertices, corresponding to temporal events and are linked to all semantic vertices observed at a particular time \cite{anokhin2024arigraphlearningknowledgegraph}. While this agent was originally designed for text-based interaction games, its competitive performance on question answering benchmarks suggests that agent-based architectures could be leveraged to implement robust systems for a broader range of natural language processing tasks.

\noindent In this work, we present a systematic evaluation of multiple agent-based architectures, largely inspired by the \textit{Cognitive Language Agent} framework, to implement robust systems for solving two natural language long-input tasks, Question Answering, and Multi-Hop Question Answering. Each system is characterized by its own internal action space, determined primarily by its underlying memory storage mechanism: vectors, graphs, or a novel hybrid system. These agents take a user query as input, reason through the question, and iteratively plan and perform actions supported by their respective systems until they have gathered sufficient information to generate a confident response, effectively leveraging agents' reflection and decision-making capabilities.




