\cleardoublepage
\chapter{Related Work}
\label{ch:relatedwork}
\label{ch:chapter2}

\section{Long-Context LLMs}

Novel model architectures have been proposed to extend the effective context window length that use transformer variants with modified attention mechanisms like recurrence. Alternatively, some studies suggest fine-tuning LLMs with positional embeddings. However, these methods are still in their early stages and incur high training costs. \\

\noindent Wang et al. proposed a model architecture that incorporates a residual side network, which serves as long-term memory storage for the LLM \cite{wang2023augmentinglanguagemodelslongterm}.

\section{Retrieval Augmented Generation}

Retrieval Augmented Generation enhances LLMs by integrating relevant knowledge from external data sources into their context \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. This strategy has been widely used to implement long-term memory for LLM conversational agents, where relevant memories are retrieved and then used to generate responses \cite{zeng2024structuralmemoryllmagents}. \\ 

\noindent Various studies have explored different retrieval granularities, including chunks, summaries, and knowledge triples \cite{zeng2024structuralmemoryllmagents}, as well as different retrieval algorithms such as BM25 and semantic similarity.\\

\noindent Graph RAG extends this approach by using an LLM to extract entities and relationships from a corpus, constructing a knowledge graph that enables more effective reasoning over the data. This structured representation helps answer global questions where conventional RAG methods often underperform \cite{edge2024localglobalgraphrag}.

\section{Prompting Methods}

Numerous prompting methods have been developed to exploit the capabilities of LLMs, enabling them to reason over intricate datasets. Techniques such as Chain of thought (CoT) and few-shot prompting have demonstrated impressive results in tackling complex tasks, including mathematical reasoning \cite{wei2023chainofthoughtpromptingelicitsreasoning}. In the context of long inputs, Sun et al. recently introduced a prompting framework called \textit{PEARL} (\textbf{P}lanning with \textbf{E}xecutable Actions for \textbf{R}easoning over \textbf{L}ong documents), which consists of three stages. First, an LLM is prompted to generate a list of actions that could help answer a question about the document. Second, the LLM formulates a plan that outlines the execution of actions from the previous step. Finally, the LLM executes the plan to generate the final answer. This approach uses the output of each action to inform the next step, ultimately guiding the model to generate a correct answer \cite{sun-etal-2024-pearl}. Similarly, Yue et al. proposed \textit{Iterative Demonstration-Based RAG}, a method designed to handle complex queries by decomposing them into simpler sub-queries. RAG is then applied to each subquery, leading to improved performance over conventional RAG \cite{yue2024inferencescalinglongcontextretrieval}.
